{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "For more information, read [Cho et al, 2020].\n",
    "1. station - used weather station number: 1 to 25\n",
    "2. Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')\n",
    "3. Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Â°C): 20 to 37.6\n",
    "4. Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Â°C): 11.3 to 29.9\n",
    "5. LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.5\n",
    "6. LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 100\n",
    "7. LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Â°C): 17.6 to 38.5\n",
    "8. LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Â°C): 14.3 to 29.6\n",
    "9. LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.9\n",
    "10. LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.4\n",
    "11. LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.97\n",
    "12. LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.97\n",
    "13. LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.98\n",
    "14. LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.97\n",
    "15. LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.7\n",
    "16. LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.6\n",
    "17. LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.8\n",
    "18. LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.7\n",
    "19. lat - Latitude (Â°): 37.456 to 37.645\n",
    "20. lon - Longitude (Â°): 126.826 to 127.135\n",
    "21. DEM - Elevation (m): 12.4 to 212.3\n",
    "22. Slope - Slope (Â°): 0.1 to 5.2\n",
    "23. Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.9\n",
    "24. Next_Tmax - The next-day maximum air temperature (Â°C): 17.4 to 38.9\n",
    "25. Next_Tmin - The next-day minimum air temperature (Â°C): 11.3 to 29.8T\n",
    "\n",
    "Please note that there are two target variables here: \n",
    "\n",
    "1) Next_Tmax: Next day maximum temperature\n",
    "\n",
    "2) Next_Tmin: Next day  minimum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore #to remove outliers\n",
    "from scipy.stats import skew\n",
    "import requests\n",
    "import pandas_profiling\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"temperature.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape # check the data dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[[\"day\",\"month\",\"year\"]] = df[\"Date\"].str.split(\"-\", expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Date\"], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"day\"] = df[\"day\"].astype(float)\n",
    "df[\"month\"] = df[\"month\"].astype(float)\n",
    "df[\"year\"] = df[\"year\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking the distribution of values of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    print(col)\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.kdeplot(df[col], shade = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_profile = df.profile_report(title=\"temperature forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove outliers before skewness check and before x, y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.boxplot(figsize=[20,8])\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Removing outliers by z score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z = np.abs(zscore(df))\n",
    "new_df = df[(z<3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloss = ((7752-0)/7752)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data loss is high, hence not dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna(value=df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check co-relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Arrange co-relation in descending order. Dropping columns should be the last option to prevent data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[22,12])\n",
    "cor = df.corr()\n",
    "sns.heatmap(cor, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cor[\"Next_Tmin\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = ['station', 'Present_Tmax', 'Present_Tmin', 'LDAPS_RHmin', 'LDAPS_RHmax',\n",
    "       'LDAPS_Tmax_lapse', 'LDAPS_Tmin_lapse', 'LDAPS_WS', 'LDAPS_LH',\n",
    "       'LDAPS_CC1', 'LDAPS_CC2', 'LDAPS_CC3', 'LDAPS_CC4', 'LDAPS_PPT1',\n",
    "       'LDAPS_PPT2', 'LDAPS_PPT3', 'LDAPS_PPT4', 'lat', 'lon', 'DEM', 'Slope',\n",
    "       'Solar radiation', 'Next_Tmax', 'Next_Tmin', 'day', 'month', 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Tmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check for skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = df.drop('Next_Tmax',axis=1)\n",
    "y = df['Next_Tmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    print(col)\n",
    "    print(skew(df[col]))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.distplot(df[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x.skew() # check skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "df_new = power_transform(x)\n",
    "\n",
    "df_new = pd.DataFrame(df_new, columns = x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the best random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(1,200):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.30, random_state = i)\n",
    "    LR = LinearRegression()\n",
    "    LR.fit(x_train, y_train)\n",
    "    predLR = LR.predict(x_test)\n",
    "    acc = r2_score(y_test, predLR)\n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS=i\n",
    "print(\"Best accuracy is\", maxAccu,\" on Random State \",maxRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(x_train, y_train)\n",
    "predLR = LR.predict(x_test)\n",
    "acc = r2_score(y_test, predLR)\n",
    "acc\n",
    "plt.scatter(y_test,predLR,color='b')\n",
    "plt.plot(y_test,y_test, color='r')\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predLR))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predLR))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predLR)))\n",
    "print('Variance:', metrics.explained_variance_score(y_test, predLR))\n",
    "print('R2 Score:', r2_score(y_test, predLR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for j in range(2,10):\n",
    "    cv_score = cross_val_score(LR, x, y, cv = j)\n",
    "    cv_mean = cv_score.mean()\n",
    "    print(f\"At cross fold {j} the cv score is {cv_mean} and accuracy score for training is {acc}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since number of folds don't have much impact on the accuracy and cv_score, \n",
    "#cv = 5 is selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters = {'alpha': [.0001, .001, .01, 1, 10], 'random_state': list(range(0,10))}\n",
    "ls = Lasso()\n",
    "clf = GridSearchCV(ls, parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = Lasso(alpha=0.0001, random_state= 0)\n",
    "ls.fit(x_train, y_train)\n",
    "ls.score(x_train, y_train)\n",
    "\n",
    "pred_ls = ls.predict(x_test)\n",
    "\n",
    "lss = r2_score(y_test, pred_ls)\n",
    "lss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=10,learning_rate=0.5,depth=2)\n",
    "# Fit model\n",
    "model.fit(x_train,y_train)\n",
    "# Get predictions\n",
    "preds = model.predict(x_test)\n",
    "\n",
    "plt.scatter(y_test,preds,color='b')\n",
    "plt.plot(y_test,y_test, color='r')\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, preds))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, preds))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "print('R2 Score', r2_score(y_test, preds))\n",
    "print('Variance:',metrics.explained_variance_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#decisiontreeregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=5)\n",
    "regr_1.fit(x_train,y_train)\n",
    "\n",
    "# Predict\n",
    "preds = regr_1.predict(x_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(y_test,preds,color='b')\n",
    "plt.plot(y_test,y_test, color='r')\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, preds))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, preds))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "print('Variance:',metrics.explained_variance_score(y_test, preds))\n",
    "print('R2 Score:',metrics.r2_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid = {'max_depth': range(1, 11),\n",
    "                                'min_samples_split': range(10, 60, 10)},\n",
    "                  cv=5,\n",
    "                  n_jobs=1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(-gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model = DecisionTreeRegressor(max_depth=10,\n",
    "                                  min_samples_split=20)\n",
    "new_model.fit(x_train, y_train)\n",
    "preds = new_model.predict(x_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(y_test,preds,color='b')\n",
    "plt.plot(y_test,y_test, color='r')\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, preds))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, preds))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "print('Variance:',metrics.explained_variance_score(y_test, preds))\n",
    "print('R2 Score:',metrics.r2_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Tmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check for skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = df.drop('Next_Tmin',axis=1)\n",
    "y = df['Next_Tmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x.skew() # check skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "df_new = power_transform(x)\n",
    "\n",
    "df_new = pd.DataFrame(df_new, columns = x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the best random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(1,200):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.30, random_state = i)\n",
    "    LR = LinearRegression()\n",
    "    LR.fit(x_train, y_train)\n",
    "    predLR = LR.predict(x_test)\n",
    "    acc = r2_score(y_test, predLR)\n",
    "    if acc > maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRS=i\n",
    "print(\"Best accuracy is\", maxAccu,\" on Random State \",maxRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(x_train, y_train)\n",
    "predLR = LR.predict(x_test)\n",
    "acc = r2_score(y_test, predLR)\n",
    "acc\n",
    "plt.scatter(y_test,predLR,color='b')\n",
    "plt.plot(y_test,y_test, color='r')\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predLR))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predLR))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predLR)))\n",
    "print('Variance:', metrics.explained_variance_score(y_test, predLR))\n",
    "print('R2 Score:', r2_score(y_test, predLR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for j in range(2,10):\n",
    "    cv_score = cross_val_score(LR, x, y, cv = j)\n",
    "    cv_mean = cv_score.mean()\n",
    "    print(f\"At cross fold {j} the cv score is {cv_mean} and accuracy score for training is {acc}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since number of folds don't have much impact on the accuracy and cv_score, \n",
    "#cv = 5 is selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters = {'alpha': [.0001, .001, .01, 1, 10], 'random_state': list(range(0,10))}\n",
    "ls = Lasso()\n",
    "clf = GridSearchCV(ls, parameters)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = Lasso(alpha=0.0001, random_state= 0)\n",
    "ls.fit(x_train, y_train)\n",
    "ls.score(x_train, y_train)\n",
    "\n",
    "pred_ls = ls.predict(x_test)\n",
    "\n",
    "lss = r2_score(y_test, pred_ls)\n",
    "lss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=10,learning_rate=0.5,depth=2)\n",
    "# Fit model\n",
    "model.fit(x_train,y_train)\n",
    "# Get predictions\n",
    "preds = model.predict(x_test)\n",
    "\n",
    "plt.scatter(y_test,preds,color='b')\n",
    "plt.plot(y_test,y_test, color='r')\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, preds))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, preds))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "print('R2 Score', r2_score(y_test, preds))\n",
    "print('Variance:',metrics.explained_variance_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#decisiontreeregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=5)\n",
    "regr_1.fit(x_train,y_train)\n",
    "\n",
    "# Predict\n",
    "preds = regr_1.predict(x_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(y_test,preds,color='b')\n",
    "plt.plot(y_test,y_test, color='r')\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, preds))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, preds))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "print('Variance:',metrics.explained_variance_score(y_test, preds))\n",
    "print('R2 Score:',metrics.r2_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid = {'max_depth': range(1, 11),\n",
    "                                'min_samples_split': range(10, 60, 10)},\n",
    "                  cv=5,\n",
    "                  n_jobs=1,\n",
    "                  scoring='neg_mean_squared_error')\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(-gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model_Tmin = DecisionTreeRegressor(max_depth=9,\n",
    "                                  min_samples_split=20)\n",
    "new_model_Tmin.fit(x_train, y_train)\n",
    "preds = new_model_Tmin.predict(x_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(y_test,preds,color='b')\n",
    "plt.plot(y_test,y_test, color='r')\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, preds))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, preds))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "print('Variance:',metrics.explained_variance_score(y_test, preds))\n",
    "print('R2 Score:',metrics.r2_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(new_model, \"Tmaxmodel.pkl\") \n",
    "joblib.dump(new_model_Tmin, \"Tminmodel.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
